"""
A stack that creates and populates a S3 bucket with
a parquet file per outcode.

Each file contains a list of ballots per UK address (from AddressBase).

This is generated from the AddressBase stack geo-joined with a CSV of
current elections.

The list of current elections is generated by EE. An update to that
list will trigger a re-build of this data package.

"""

from typing import List

import aws_cdk.aws_lambda_python_alpha as aws_lambda_python
from aws_cdk import (
    CfnOutput,
    Duration,
    Fn,
    aws_events,
    aws_events_targets,
    aws_lambda,
    aws_sqs,
)
from aws_cdk import (
    aws_iam as iam,
)
from aws_cdk import aws_stepfunctions as sfn
from aws_cdk import aws_stepfunctions_tasks as tasks
from constructs import Construct
from shared_components.buckets import (
    ee_data_cache_production,
    pollingstations_private_data,
)
from shared_components.constructs.addressbase_source_check_construct import (
    AddressBaseSourceCheckConstruct,
)
from shared_components.constructs.guarded_step_function_construct import (
    GuardedStepFunctionConstruct,
)
from shared_components.constructs.make_partitions_construct import (
    MakePartitionsConstruct,
)
from shared_components.constructs.step_function_event_queue_construct import (
    StepFunctionEventQueueConstruct,
)
from shared_components.models import GlueTable, S3Bucket
from shared_components.tables import (
    current_ballots,
    current_ballots_joined_to_address_base,
)
from stacks.base_stack import DataBakerStack


class CurrentElectionsStack(DataBakerStack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)
        self.athena_query_lambda_arn = Fn.import_value(
            "RunAthenaQueryArnOutput"
        )
        self.athena_query_lambda = aws_lambda.Function.from_function_arn(
            self, "RunAthenaQuery", self.athena_query_lambda_arn
        )
        self.empty_bucket_by_prefix = Fn.import_value(
            "EmptyS3BucketByPrefixArnOutput"
        )
        self.empty_bucket_by_prefix_lambda = (
            aws_lambda.Function.from_function_arn(
                self, "EmptyS3BucketByPrefix", self.empty_bucket_by_prefix
            )
        )

        self.first_letter_to_outcode_parquet_lambda_arn = Fn.import_value(
            "FirstLetterToOutcodeParquetLambdaArnOutput"
        )

        self.first_letter_to_outcode_parquet_lambda = (
            aws_lambda.Function.from_function_arn(
                self,
                "FirstLetterToOutcodeParquet",
                self.first_letter_to_outcode_parquet_lambda_arn,
            )
        )

        delete_old_current_ballots_joined_to_addressbase_task = (
            self.make_delete_old_current_ballots_joined_to_addressbase_task()
        )

        parallel_first_letter_task = self.make_parallel_first_letter_task()

        make_partitions = self.make_partitions_task(
            current_ballots_joined_to_address_base
        )

        # Fan-out step (for each letter A-Z)
        parallel_outcodes_task = self.make_parallel_outcodes_task()

        create_current_csv_task = self.make_create_current_csv_task()

        addressbase_check = AddressBaseSourceCheckConstruct(
            self,
            "AddressBaseSourceCheck",
            athena_query_lambda=self.athena_query_lambda,
            table_name=current_ballots_joined_to_address_base.table_name,
        )

        main_tasks = (
            delete_old_current_ballots_joined_to_addressbase_task.next(
                create_current_csv_task
            )
            .next(parallel_first_letter_task)
            .next(make_partitions)
            .next(parallel_outcodes_task)
            .next(addressbase_check.entry_point)
        )

        self.step_function = GuardedStepFunctionConstruct(
            self,
            "MakeCurrentElectionsParquet ",
            step_function_name="MakeCurrentElectionsParquet",
            main_tasks=main_tasks,
        ).entry_point

        self.make_event_triggers()

        CfnOutput(
            self,
            "MakeCurrentElectionsParquetArnOutput",
            value=self.step_function.state_machine_arn,
            export_name="MakeCurrentElectionsParquetArn",
        )

    @staticmethod
    def glue_tables() -> List[GlueTable]:
        return [current_ballots, current_ballots_joined_to_address_base]

    @staticmethod
    def s3_buckets() -> List[S3Bucket]:
        return [ee_data_cache_production, pollingstations_private_data]

    def make_create_current_csv_task(self) -> tasks.LambdaInvoke:
        create_current_elections_csv_function = aws_lambda_python.PythonFunction(
            self,
            "create_current_elections_csv",
            function_name="create_current_elections_csv",
            runtime=aws_lambda.Runtime.PYTHON_3_12,
            handler="handler",
            entry="cdk/shared_components/lambdas/create_current_elections_csv",
            index="create_current_elections_csv.py",
            timeout=Duration.seconds(900),
            memory_size=2048,
        )

        create_current_elections_csv_function.add_to_role_policy(
            iam.PolicyStatement(
                actions=[
                    "ssm:*",
                    "s3:*",
                ],
                resources=["*"],
            )
        )

        return tasks.LambdaInvoke(
            self,
            "Make current elections CSV",
            lambda_function=create_current_elections_csv_function,
        )

    def make_event_triggers(self):
        event_queue = StepFunctionEventQueueConstruct(
            self,
            "MakeCurrentElectionsEventQueue",
            target_step_function=self.step_function,
            queue_name="CurrentElectionsEventQueue",
            pipe_name="RunCurrentElectionsBuilder",
        ).entry_point

        self.make_run_nightly_rule(event_queue)
        self.make_rebuild_election_parquet_rule(event_queue)

    def make_run_nightly_rule(self, event_queue: aws_sqs.IQueue):
        one_am = aws_events.Schedule.cron(minute="0", hour="1")
        run_nightly_rule = aws_events.Rule(
            self, "RebuildCurrentElectionsNightlyTrigger", schedule=one_am
        )

        run_nightly_rule.add_target(
            aws_events_targets.SqsQueue(
                event_queue,
                message=aws_events.RuleTargetInput.from_text("Nightly re-run"),
                message_group_id="elections_set_changed",
            )
        )

    def make_rebuild_election_parquet_rule(self, event_queue: aws_sqs.IQueue):
        aws_events.Rule(
            self,
            "RebuildCurrentElectionsParquetTrigger",
            targets=[
                aws_events_targets.SqsQueue(
                    event_queue,
                    message_group_id="elections_set_changed",
                ),
            ],
            event_pattern=aws_events.EventPattern(
                detail_type=["elections_set_changed"]
            ),
        )

    def make_delete_old_current_ballots_joined_to_addressbase_task(
        self,
    ) -> tasks.LambdaInvoke:
        return tasks.LambdaInvoke(
            self,
            "Remove old data from S3",
            lambda_function=self.empty_bucket_by_prefix_lambda,
            payload=sfn.TaskInput.from_object(
                {
                    "bucket": current_ballots_joined_to_address_base.bucket.bucket_name,
                    "prefix": current_ballots_joined_to_address_base.s3_prefix.format(
                        **self.context
                    ),
                }
            ),
        )

    def make_partitions_task(self, table) -> tasks.LambdaInvoke:
        return MakePartitionsConstruct(
            self,
            f"Make partitions For{table.table_name}",
            athena_query_lambda=self.athena_query_lambda,
            target_table_name=table.table_name,
        ).entry_point

    def make_parallel_outcodes_task(self) -> sfn.Parallel:
        parallel_outcodes = sfn.Parallel(
            self, "Make outcode parquet per first letter"
        )
        alphabet = [chr(i) for i in range(ord("A"), ord("Z") + 1)]
        for letter in alphabet:
            context = current_ballots_joined_to_address_base.populated_with.context.copy()
            context["first_letter"] = letter

            parallel_outcodes.branch(
                tasks.LambdaInvoke(
                    self,
                    f"Make outcode parquet for {letter}",
                    lambda_function=self.first_letter_to_outcode_parquet_lambda,
                    payload=sfn.TaskInput.from_object(
                        {
                            "first_letter": letter,
                            "source_bucket_name": current_ballots_joined_to_address_base.bucket.bucket_name,
                            "source_path": current_ballots_joined_to_address_base.s3_prefix.format(
                                dc_environment=self.dc_environment
                            ),
                            "dest_bucket_name": pollingstations_private_data.bucket_name,
                            "dest_path": f"addressbase/{self.dc_environment}/current_elections_parquet",
                            "filter_column": "ballot_ids",
                        }
                    ),
                )
            )
        return parallel_outcodes

    def make_parallel_first_letter_task(self) -> sfn.Parallel:
        # Fan-out step (for each letter A-Z)
        parallel_execution = sfn.Parallel(self, "Fan Out Letters")
        alphabet = [chr(i) for i in range(ord("A"), ord("Z") + 1)]
        for letter in alphabet:
            context = current_ballots_joined_to_address_base.populated_with.context.copy()
            context["first_letter"] = letter

            parallel_execution.branch(
                tasks.LambdaInvoke(
                    self,
                    f"Process {letter}",
                    lambda_function=self.athena_query_lambda,
                    payload=sfn.TaskInput.from_object(
                        {
                            "context": context,
                            "QueryName": current_ballots_joined_to_address_base.populated_with.name,
                            "blocking": True,
                        }
                    ),
                )
            )
        return parallel_execution
