"""
A stack that creates and populates a S3 bucket with
a parquet file per outcode.

Each file contains a list of ballots per UK address (from AddressBase).

This is generated from the AddressBase stack geo-joined with a CSV of
current elections.

The list of current elections is generated by EE. An update to that
list will trigger a re-build of this data package.

"""

from typing import List

import aws_cdk.aws_lambda_python_alpha as aws_lambda_python
import aws_cdk.aws_pipes_alpha as aws_pipes_alpha
import aws_cdk.aws_pipes_sources_alpha as aws_pipes_sources_alpha
import aws_cdk.aws_pipes_targets_alpha as aws_pipes_targets_alpha
from aws_cdk import (
    CfnOutput,
    Duration,
    Fn,
    aws_events,
    aws_events_targets,
    aws_lambda,
    aws_sqs,
)
from aws_cdk import (
    aws_iam as iam,
)
from aws_cdk import aws_stepfunctions as sfn
from aws_cdk import aws_stepfunctions_tasks as tasks
from constructs import Construct
from shared_components.buckets import (
    ee_data_cache_production,
    pollingstations_private_data,
)
from shared_components.constructs.addressbase_source_check_construct import (
    AddressBaseSourceCheckConstruct,
)
from shared_components.models import GlueTable, S3Bucket
from shared_components.tables import (
    current_ballots,
    current_ballots_joined_to_address_base,
)
from stacks.base_stack import DataBakerStack


class CurrentElectionsStack(DataBakerStack):
    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)
        self.athena_query_lambda_arn = Fn.import_value(
            "RunAthenaQueryArnOutput"
        )
        self.athena_query_lambda = aws_lambda.Function.from_function_arn(
            self, "RunAthenaQuery", self.athena_query_lambda_arn
        )
        self.empty_bucket_by_prefix = Fn.import_value(
            "EmptyS3BucketByPrefixArnOutput"
        )
        self.empty_bucket_by_prefix_lambda = (
            aws_lambda.Function.from_function_arn(
                self, "EmptyS3BucketByPrefix", self.empty_bucket_by_prefix
            )
        )
        self.check_step_function_running = Fn.import_value(
            "CheckStepFunctionRunningArnOutput"
        )
        self.check_step_function_running_function = (
            aws_lambda.Function.from_function_arn(
                self,
                "CheckStepFunctionRunningArnOutput",
                self.check_step_function_running,
            )
        )

        delete_old_current_ballots_joined_to_addressbase_task = (
            self.make_delete_old_current_ballots_joined_to_addressbase_task()
        )

        parallel_first_letter_task = self.make_parallel_first_letter_task()

        make_partitions = self.make_partitions_task()

        # Fan-out step (for each letter A-Z)
        parallel_outcodes_task = self.make_parallel_outcodes_task()

        create_current_csv_task = self.make_create_current_csv_task()

        addressbase_check = AddressBaseSourceCheckConstruct(
            self,
            "AddressBaseSourceCheck",
            athena_query_lambda=self.athena_query_lambda,
            table_name=current_ballots_joined_to_address_base.table_name,
        )

        main_tasks = (
            delete_old_current_ballots_joined_to_addressbase_task.next(
                create_current_csv_task
            )
            .next(parallel_first_letter_task)
            .next(make_partitions)
            .next(parallel_outcodes_task)
            .next(addressbase_check.entry_point)
        )

        should_run_decision = self.make_should_run_decision(main_tasks)
        check_step_function_running_task = (
            self.make_check_step_function_running_task()
        )
        state_definition = check_step_function_running_task.next(
            should_run_decision
        )

        self.step_function = sfn.StateMachine(
            self,
            "MakeCurrentElectionsParquet",
            state_machine_name="MakeCurrentElectionsParquet",
            definition=state_definition,
            timeout=Duration.minutes(10),
        )

        self.make_event_triggers()

        CfnOutput(
            self,
            "MakeCurrentElectionsParquetArnOutput",
            value=self.step_function.state_machine_arn,
            export_name="MakeCurrentElectionsParquetArn",
        )

    @staticmethod
    def glue_tables() -> List[GlueTable]:
        return [current_ballots, current_ballots_joined_to_address_base]

    @staticmethod
    def s3_buckets() -> List[S3Bucket]:
        return [ee_data_cache_production, pollingstations_private_data]

    def make_should_run_decision(self, main_tasks) -> sfn.Choice:
        fail_state = sfn.Fail(
            self,
            "StopExecution",
            cause="ConcurrentExecution",
            error="AnotherExecutionRunning",
        )
        decision = sfn.Choice(self, "CanProceed?")
        decision.when(
            sfn.Condition.boolean_equals("$.proceed", True), main_tasks
        )
        decision.otherwise(fail_state)
        return decision

    def make_check_step_function_running_task(self) -> tasks.LambdaInvoke:
        return tasks.LambdaInvoke(
            self,
            "CheckConcurrentExecution",
            lambda_function=self.check_step_function_running_function,
            payload=sfn.TaskInput.from_object(
                {
                    "stateMachineArn.$": "$$.StateMachine.Id",
                    "currentExecutionArn.$": "$$.Execution.Id",
                }
            ),
            output_path="$.Payload",
        )

    def make_create_current_csv_task(self) -> tasks.LambdaInvoke:
        create_current_elections_csv_function = aws_lambda_python.PythonFunction(
            self,
            "create_current_elections_csv",
            function_name="create_current_elections_csv",
            runtime=aws_lambda.Runtime.PYTHON_3_12,
            handler="handler",
            entry="cdk/shared_components/lambdas/create_current_elections_csv",
            index="create_current_elections_csv.py",
            timeout=Duration.seconds(900),
            memory_size=2048,
        )

        create_current_elections_csv_function.add_to_role_policy(
            iam.PolicyStatement(
                actions=[
                    "ssm:*",
                    "s3:*",
                ],
                resources=["*"],
            )
        )

        return tasks.LambdaInvoke(
            self,
            "Make current elections CSV",
            lambda_function=create_current_elections_csv_function,
        )

    def make_event_triggers(self):
        event_queue = aws_sqs.Queue(
            self,
            "CurrentElectionsEventQueue",
            fifo=True,
            content_based_deduplication=True,
            queue_name="CurrentElectionsEventQueue.fifo",
            encryption=aws_sqs.QueueEncryption.UNENCRYPTED,
            delivery_delay=Duration.minutes(5),
        )

        self.make_run_nightly_rule(event_queue)
        self.make_sqs_to_sfn_pipe(event_queue)

    def make_sqs_to_sfn_pipe(self, event_queue):
        pipe_role = iam.Role(
            self,
            "PipeRole",
            assumed_by=iam.ServicePrincipal("pipes.amazonaws.com"),
        )
        pipe_role.add_to_policy(
            iam.PolicyStatement(
                actions=[
                    "sqs:ReceiveMessage",
                    "sqs:DeleteMessage",
                    "sqs:GetQueueAttributes",
                ],
                resources=[event_queue.queue_arn],
            )
        )
        pipe_role.add_to_policy(
            iam.PolicyStatement(
                actions=["states:StartExecution"],
                resources=[self.step_function.state_machine_arn],
            )
        )

        aws_pipes_alpha.Pipe(
            self,
            "RunCurrentElectionsBuilder",
            role=pipe_role,
            source=aws_pipes_sources_alpha.SqsSource(
                event_queue,
            ),
            target=aws_pipes_targets_alpha.SfnStateMachine(
                self.step_function,
                invocation_type=aws_pipes_targets_alpha.StateMachineInvocationType.FIRE_AND_FORGET,
            ),
        )

    def make_run_nightly_rule(self, event_queue: aws_sqs.Queue):
        one_am = aws_events.Schedule.cron(minute="0", hour="1")
        run_nightly_rule = aws_events.Rule(
            self, "RebuildCurrentElectionsNightlyTrigger", schedule=one_am
        )

        run_nightly_rule.add_target(
            aws_events_targets.SqsQueue(
                event_queue,
                message=aws_events.RuleTargetInput.from_text("Nightly re-run"),
                message_group_id="elections_set_changed",
            )
        )

    def make_delete_old_current_ballots_joined_to_addressbase_task(
        self,
    ) -> tasks.LambdaInvoke:
        return tasks.LambdaInvoke(
            self,
            "Remove old data from S3",
            lambda_function=self.empty_bucket_by_prefix_lambda,
            payload=sfn.TaskInput.from_object(
                {
                    "bucket": current_ballots_joined_to_address_base.bucket.bucket_name,
                    "prefix": current_ballots_joined_to_address_base.s3_prefix.format(
                        **self.context
                    ),
                }
            ),
        )

    def make_partitions_task(self) -> tasks.LambdaInvoke:
        return tasks.LambdaInvoke(
            self,
            "Make partitions",
            lambda_function=self.athena_query_lambda,
            payload=sfn.TaskInput.from_object(
                {
                    "context": {
                        "table_name": current_ballots_joined_to_address_base.table_name
                    },
                    "QueryString": "MSCK REPAIR TABLE `$table_name`;",
                    "blocking": True,
                }
            ),
        )

    def make_to_outcode_parquet_task(self) -> tasks.LambdaInvoke:
        to_outcode_parquet = aws_lambda_python.PythonFunction(
            self,
            "first_letter_to_outcode_parquet",
            function_name="first_letter_to_outcode_parquet",
            runtime=aws_lambda.Runtime.PYTHON_3_12,
            handler="handler",
            entry="cdk/shared_components/lambdas/first_letter_to_outcode_parquet/",
            index="first_letter_to_outcode_parquet.py",
            timeout=Duration.seconds(900),
            memory_size=2048,
        )

        to_outcode_parquet.add_to_role_policy(
            iam.PolicyStatement(
                actions=[
                    "athena:*",
                    "s3:*",
                    "glue:*",
                ],
                resources=["*"],
            )
        )

        return to_outcode_parquet

    def make_parallel_outcodes_task(self) -> sfn.Parallel:
        to_outcode_parquet = self.make_to_outcode_parquet_task()
        parallel_outcodes = sfn.Parallel(
            self, "Make outcode parquet per first letter"
        )
        alphabet = [chr(i) for i in range(ord("A"), ord("Z") + 1)]
        for letter in alphabet:
            context = current_ballots_joined_to_address_base.populated_with.context.copy()
            context["first_letter"] = letter

            parallel_outcodes.branch(
                tasks.LambdaInvoke(
                    self,
                    f"Make outcode parquet for {letter}",
                    lambda_function=to_outcode_parquet,
                    payload=sfn.TaskInput.from_object(
                        {
                            "first_letter": letter,
                            "source_bucket_name": current_ballots_joined_to_address_base.bucket.bucket_name,
                            "source_path": current_ballots_joined_to_address_base.s3_prefix.format(
                                dc_environment=self.dc_environment
                            ),
                            "dest_bucket_name": pollingstations_private_data.bucket_name,
                            "dest_path": f"addressbase/{self.dc_environment}/current_elections_parquet",
                        }
                    ),
                )
            )
        return parallel_outcodes

    def make_parallel_first_letter_task(self) -> sfn.Parallel:
        # Fan-out step (for each letter A-Z)
        parallel_execution = sfn.Parallel(self, "Fan Out Letters")
        alphabet = [chr(i) for i in range(ord("A"), ord("Z") + 1)]
        for letter in alphabet:
            context = current_ballots_joined_to_address_base.populated_with.context.copy()
            context["first_letter"] = letter

            parallel_execution.branch(
                tasks.LambdaInvoke(
                    self,
                    f"Process {letter}",
                    lambda_function=self.athena_query_lambda,
                    payload=sfn.TaskInput.from_object(
                        {
                            "context": context,
                            "QueryName": current_ballots_joined_to_address_base.populated_with.name,
                            "blocking": True,
                        }
                    ),
                )
            )
        return parallel_execution
